{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet model implemented with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage import color\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "# os.environ['KERAS_BACKEND'] = 'theano'\n",
    "# os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN, device=gpu0, floatX=float32, optimizer=fast_compile'\n",
    "\n",
    "from tensorflow.contrib.keras.python.keras import models\n",
    "from tensorflow.contrib.keras.python.keras.optimizers import SGD, Adam\n",
    "from tensorflow.contrib.keras.python.keras.models import model_from_json\n",
    "from tensorflow.contrib.keras.python.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build model\n",
    "from tensorflow.contrib.keras.python.keras.layers.core import Activation, Reshape, Permute\n",
    "from tensorflow.contrib.keras.python.keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dropout\n",
    "from tensorflow.contrib.keras.python.keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow.contrib.keras.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "import json\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = 'Data/'\n",
    "# img_w = 256\n",
    "# img_h = 256\n",
    "\n",
    "path = ''\n",
    "# img_w = 512\n",
    "img_w = 424\n",
    "img_h = 424\n",
    "\n",
    "n_labels = 2\n",
    "\n",
    "kernel = 3\n",
    "\n",
    "n_train = 6\n",
    "n_test = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_map(labels):\n",
    "    label_map = np.zeros([img_h, img_w, n_labels])    \n",
    "    for r in range(img_h):\n",
    "        for c in range(img_w):\n",
    "            label_map[r, c, int(np.ceil(labels[r][c]))] = 1\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(mode):\n",
    "    assert mode in {'test', 'train'}, \\\n",
    "        'mode should be either \\'test\\' or \\'train\\''\n",
    "    data = []\n",
    "    label = []\n",
    "    df = pd.read_csv(path + mode + '.csv')\n",
    "    n = n_train if mode == 'train' else n_test\n",
    "    for i, item in df.iterrows():\n",
    "        if i >= n:\n",
    "            break\n",
    "#         img, gt = [imread(path + item[0])], np.clip(imread(path + item[1]), 0, 1)\n",
    "        img, gt = [resize(imread(path + item[0]), (img_h, img_w))],  resize(np.clip(~(imread(path + item[1])[:, :, 0]), 0, 1), (img_h, img_w))\n",
    "        \n",
    "        data.append(img)\n",
    "        label.append(label_map(gt))\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(mode + \": [%-20s] %d%%\" % ('=' * int(20. * (i + 1) / n - 1) + '>',\n",
    "                                                    int(100. * (i + 1) / n)))\n",
    "        sys.stdout.flush()\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.flush()\n",
    "    data, label = np.array(data).swapaxes(1, 3), np.array(label).reshape((n, img_h * img_w, n_labels))\n",
    "\n",
    "    print(mode + ': OK')\n",
    "    print('\\tshapes: {}, {}'.format(data.shape, label.shape))\n",
    "    print('\\ttypes:  {}, {}'.format(data.dtype, label.dtype))\n",
    "    print('\\tmemory: {}, {} MB'.format(data.nbytes / 1048576, label.nbytes / 1048576))\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fn = 'E:/fingerpaint_dataset_segnet/data/labels/combinedSubjectC_labels/combinedSubjectC_labels_0004.png'\n",
    "# fn = 'E:/fingerpaint_dataset_segnet/data/depth/combinedSubjectC_depth/combinedSubjectC_depth_0004.png'\n",
    "\n",
    "img = resize(np.clip(~(imread(fn)[:, :, 0]), 0, 1), (img_h, img_w))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "label = []\n",
    "label.append(label_map(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(output):\n",
    "    gt = []\n",
    "    df = pd.read_csv(path + 'test.csv')\n",
    "    for i, item in df.iterrows():\n",
    "        gt.append(np.clip(imread(path + item[1]), 0, 1))\n",
    "\n",
    "    plt.figure(figsize=(15, 2 * n_test))\n",
    "    for i, item in df.iterrows():\n",
    "        plt.subplot(n_test, 5, 5 * i + 1)\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "        im = imread(path + item[0])\n",
    "        plt.imshow(im, cmap='gray')\n",
    "        \n",
    "        plt.subplot(n_test, 5, 5 * i + 2)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "        gt = imread(path + item[1])\n",
    "        plt.imshow(np.clip(gt, 0, 1), cmap='gray')\n",
    "\n",
    "        plt.subplot(n_test, 5, 5 * i + 3)\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "        labeled = np.argmax(output[i], axis=-1)\n",
    "        plt.imshow(labeled, cmap='gray')\n",
    "\n",
    "        plt.subplot(n_test, 5, 5 * i + 4)\n",
    "        plt.title('Heat map')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(output[i][:, :, 1])\n",
    "\n",
    "        plt.subplot(n_test, 5, 5 * i + 5)\n",
    "        plt.title('Comparison')\n",
    "        plt.axis('off')\n",
    "        rgb = np.empty((img_h, img_w, 3))\n",
    "        rgb[:, :, 0] = labeled\n",
    "        rgb[:, :, 1] = imread(path + item[0])\n",
    "        rgb[:, :, 2] = gt\n",
    "        plt.imshow(rgb)\n",
    "\n",
    "    plt.savefig('result.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_layers = [\n",
    "    Conv2D(64, (kernel, kernel), padding='same', input_shape=(img_h, img_w, 1)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(128, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(128, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(256, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "]\n",
    "\n",
    "autoencoder = models.Sequential()\n",
    "autoencoder.encoding_layers = encoding_layers\n",
    "\n",
    "for l in autoencoder.encoding_layers:\n",
    "    autoencoder.add(l)\n",
    "    \n",
    "# print(autoencoder.summary())\n",
    "\n",
    "decoding_layers = [\n",
    "    UpSampling2D(),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "\n",
    "    UpSampling2D(),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "\n",
    "    UpSampling2D(),\n",
    "    Conv2D(256, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(128, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "\n",
    "    UpSampling2D(),\n",
    "    Conv2D(128, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "\n",
    "    UpSampling2D(),\n",
    "    Conv2D(64, (kernel, kernel), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(n_labels, (1, 1), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "]\n",
    "autoencoder.decoding_layers = decoding_layers\n",
    "for l in autoencoder.decoding_layers:\n",
    "    autoencoder.add(l)\n",
    "\n",
    "autoencoder.add(Reshape((n_labels, img_h * img_w)))\n",
    "autoencoder.add(Permute((2, 1)))\n",
    "# autoencoder.add(Dropout(0.5))\n",
    "autoencoder.add(Activation('softmax'))\n",
    "\n",
    "with open('model_5l.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(json.loads(autoencoder.to_json()), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and compiling model built with *'build_model.py'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('model_5l.json', 'r') as f:\n",
    "#     json_string = f.read()\n",
    "# autoencoder = model_from_json(json_string)\n",
    "\n",
    "optimizer = SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False)\n",
    "# optimizer = Adam(lr=0.001, decay=0.0005)\n",
    "autoencoder.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "print('Compiled: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model or load existing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, train_label = prep_data('train')\n",
    "test_data, test_label = prep_data('test')\n",
    "\n",
    "nb_epoch = 1000\n",
    "batch_size = 64\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
    "\n",
    "history = autoencoder.fit(train_data, train_label,\n",
    "                          batch_size=batch_size, epochs=nb_epoch,\n",
    "                          verbose=1,\n",
    "                          validation_data=(test_data, test_label),\n",
    "                          shuffle=False,\n",
    "                          callbacks=[early_stopping])\n",
    "\n",
    "autoencoder.save_weights('model_5l_weight_ep50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(train_data[0, :, :, 0], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autoencoder.load_weights('model_5l_weight_ep50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(autoencoder, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data and evaluate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data, test_label = prep_data('test')\n",
    "score = autoencoder.evaluate(test_data, test_label, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "train_data, train_label = prep_data('train')\n",
    "score = autoencoder.evaluate(train_data, train_label, verbose=0)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = autoencoder.predict_proba(test_data, verbose=0)\n",
    "# output = autoencoder.predict_proba(train_data, verbose=0)\n",
    "output = output.reshape((output.shape[0], img_h, img_w, n_labels))\n",
    "\n",
    "plot_results(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_his.pickle', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "history_ = history.history\n",
    "\n",
    "# list all data in history\n",
    "print(history_.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_['acc'])\n",
    "plt.plot(history_['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_['loss'])\n",
    "plt.plot(history_['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
