{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 57300 images found\n",
      "40110, 17190\n",
      "   ---> processed 0 files.\n",
      "   ---> processed 5000 files.\n",
      "   ---> processed 10000 files.\n",
      "   ---> processed 15000 files.\n",
      "   ---> processed 20000 files.\n",
      "   ---> processed 25000 files.\n"
     ]
    }
   ],
   "source": [
    "num_train = 0;\n",
    "num_test = 0;\n",
    "num_total = 0\n",
    "\n",
    "cur_num_train = 0;\n",
    "cur_num_test = 0;\n",
    "cur_num_total = 0\n",
    "\n",
    "for dir_path, dir_names, file_names in os.walk('E:/fingerpaint_dataset_segnet/data/depth'):\n",
    "    for file_name in [f for f in file_names if f.endswith('.png')]:\n",
    "        num_total += 1\n",
    "\n",
    "num_train = round(num_total*0.7)\n",
    "num_test = num_total - num_train\n",
    "\n",
    "print('> %d images found' % (num_total))\n",
    "print('%d, %d' % (num_train, num_test))\n",
    "\n",
    "# random training indexes\n",
    "train_indexes = random.sample(range(num_total), num_train)\n",
    "\n",
    "# write csv headers\n",
    "train_file = open('train.csv', 'w')\n",
    "train_file.write('Image,GroundTruth\\n')\n",
    "\n",
    "test_file = open('test.csv', 'w')\n",
    "test_file.write('Image,GroundTruth\\n')\n",
    "\n",
    "indx = 0\n",
    "for dir_path, dir_names, file_names in os.walk('E:/fingerpaint_dataset_segnet/data/depth'):\n",
    "    for file_name in [f for f in file_names if f.endswith('.png')]:\n",
    "        depth_img = os.path.join(dir_path, file_name).replace(\"\\\\\",\"/\")\n",
    "        label_img = os.path.join(dir_path, file_name).replace('depth', 'labels').replace(\"\\\\\",\"/\")\n",
    "        \n",
    "        # current index is in training indexes?\n",
    "        if indx in train_indexes:\n",
    "            # write to train csv\n",
    "            train_file.write(depth_img + ',' + label_img + '\\n')\n",
    "        else:\n",
    "            # write to test csv\n",
    "            test_file.write(depth_img + ',' + label_img + '\\n')\n",
    "        \n",
    "        if indx % 5000 == 0:\n",
    "            print('   ---> processed %d files.' % (indx))\n",
    "            \n",
    "        indx += 1\n",
    "\n",
    "train_file.close()\n",
    "test_file.close()\n",
    "\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
